{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/egor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pymorphy2\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование слов полей title и text к нормальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tolow(df, col):\n",
    "    df[col] = df[col].apply(str.lower)\n",
    "    return df\n",
    "\n",
    "def delInfo(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\(*\\)',' ', x))\n",
    "    return df\n",
    "\n",
    "def delShortWords(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\s\\w{1,3}\\s',' ', x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def delPunc(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'[!,\\.\\?\\*\\(\\)\"“”«»:;#№\\-@%\\+]',' ', x))\n",
    "    return df\n",
    "\n",
    "def delGreat(df, col):\n",
    "    words = [r'здравствуйте', r'добрый день', r'добрый вечер', r'доброе утро', r'приветствую']\n",
    "    for el in words:\n",
    "        df[col] = df[col].apply(lambda x: re.sub(el,' ', x))\n",
    "    return df\n",
    "\n",
    "def delWord(df, col, word):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(word,' ', x))\n",
    "    return df\n",
    "\n",
    "def delE(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'ё','е', x))\n",
    "    return df\n",
    "\n",
    "def delSpace(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\s{2,}', ' ', x))\n",
    "    return df\n",
    "\n",
    "def delDig(df, col):\n",
    "    df[col] = df[col].apply(lambda x: re.sub(r'\\d+', ' ', x))\n",
    "    return df\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "def normalize(text):\n",
    "    s = ''\n",
    "    for el in text.split(' '):\n",
    "        s+= morph.parse(el)[0].normal_form + ' '\n",
    "    return s\n",
    "\n",
    "def repl(x):\n",
    "    category = ['Кредит', 'Ипотека', 'Реструктуризация', 'Вклад', 'Бизнес услуги', 'Обслуживание физ. и юр. лиц',\n",
    "               'Дебетовая карта', 'Денежные переводы', 'Инвестиционные продукты']\n",
    "    return category.index(x)\n",
    "\n",
    "\n",
    "for el, col in zip([train, test, train, test], ['title', 'text', 'text', 'title']):\n",
    "    for f in [tolow, delInfo,  delPunc, delGreat, delE, delDig, delShortWords, delSpace]:\n",
    "        el = f(el, col)\n",
    "    el[col] = el[col].apply(lambda x: normalize(x))\n",
    "    \n",
    "train['type'] = train['type'].apply(repl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нахождение популярных осмысленных слов каждой категории для признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(string):\n",
    "    a = morph.parse(string)[0].tag\n",
    "    return (('NOUN' in a) or ('ADJF' in a) or ('INFN' in a))\n",
    "\n",
    "words_0 = pd.Series(np.concatenate(classif_train[classif_train['type']==0]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_1 = pd.Series(np.concatenate(classif_train[classif_train['type']==1]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_2 = pd.Series(np.concatenate(classif_train[classif_train['type']==2]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_3 = pd.Series(np.concatenate(classif_train[classif_train['type']==3]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_4 = pd.Series(np.concatenate(classif_train[classif_train['type']==4]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_5 = pd.Series(np.concatenate(classif_train[classif_train['type']==5]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_6 = pd.Series(np.concatenate(classif_train[classif_train['type']==6]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_7 = pd.Series(np.concatenate(classif_train[classif_train['type']==7]['text'].apply(lambda s: s.strip().split()).values))\n",
    "words_8 = pd.Series(np.concatenate(classif_train[classif_train['type']==8]['text'].apply(lambda s: s.strip().split()).values))\n",
    "\n",
    "words_0 = words_0[~words_0.isin(stopwords.words('russian'))]\n",
    "words_1 = words_1[~words_1.isin(stopwords.words('russian'))]\n",
    "words_2 = words_2[~words_2.isin(stopwords.words('russian'))]\n",
    "words_3 = words_3[~words_3.isin(stopwords.words('russian'))]\n",
    "words_4 = words_4[~words_4.isin(stopwords.words('russian'))]\n",
    "words_5 = words_5[~words_5.isin(stopwords.words('russian'))]\n",
    "words_6 = words_6[~words_6.isin(stopwords.words('russian'))]\n",
    "words_7 = words_7[~words_7.isin(stopwords.words('russian'))]\n",
    "words_8 = words_8[~words_8.isin(stopwords.words('russian'))]\n",
    "\n",
    "words_0 = words_0[words_0.str.isalpha()] # Только буквы\n",
    "words_1 = words_1[words_1.str.isalpha()] # Только буквы\n",
    "words_2 = words_2[words_2.str.isalpha()] # Только буквы\n",
    "words_3 = words_3[words_3.str.isalpha()] # Только буквы\n",
    "words_4 = words_4[words_4.str.isalpha()] # Только буквы\n",
    "words_5 = words_5[words_5.str.isalpha()] # Только буквы\n",
    "words_6 = words_6[words_6.str.isalpha()] # Только буквы\n",
    "words_7 = words_7[words_7.str.isalpha()] # Только буквы\n",
    "words_8 = words_8[words_8.str.isalpha()] # Только буквы\n",
    "\n",
    "words_0 = words_0[(words_0.str.len() >= 3)] # Длина > 2\n",
    "words_1 = words_1[(words_1.str.len() >= 3)] # Длина > 2\n",
    "words_2 = words_2[(words_2.str.len() >= 3)] # Длина > 2\n",
    "words_3 = words_3[(words_3.str.len() >= 3)] # Длина > 2\n",
    "words_4 = words_4[(words_4.str.len() >= 3)] # Длина > 2\n",
    "words_5 = words_5[(words_5.str.len() >= 3)] # Длина > 2\n",
    "words_6 = words_6[(words_6.str.len() >= 3)] # Длина > 2\n",
    "words_7 = words_7[(words_7.str.len() >= 3)] # Длина > 2\n",
    "words_8 = words_8[(words_8.str.len() >= 3)] # Длина > 2\n",
    "\n",
    "words_0 = words_0[words_0.apply(tag)]\n",
    "words_1 = words_1[words_1.apply(tag)]\n",
    "words_2 = words_2[words_2.apply(tag)]\n",
    "words_3 = words_3[words_3.apply(tag)]\n",
    "words_4 = words_4[words_4.apply(tag)]\n",
    "words_5 = words_5[words_5.apply(tag)]\n",
    "words_6 = words_6[words_6.apply(tag)]\n",
    "words_7 = words_7[words_7.apply(tag)]\n",
    "words_8 = words_8[words_8.apply(tag)]\n",
    "\n",
    "df = pd.DataFrame(columns = ['words_0','words_1','words_2','words_3','words_4','words_5','words_6','words_7','words_8'])\n",
    "\n",
    "df['words_0'] = words_0\n",
    "df['words_1'] = words_1\n",
    "df['words_2'] = words_2\n",
    "df['words_3'] = words_3\n",
    "df['words_4'] = words_4\n",
    "df['words_5'] = words_5\n",
    "df['words_6'] = words_6\n",
    "df['words_7'] = words_7\n",
    "df['words_8'] = words_8\n",
    "\n",
    "count_0 = df['words_0'].value_counts()\n",
    "count_1 = df['words_1'].value_counts()\n",
    "count_2 = df['words_2'].value_counts()\n",
    "count_3 = df['words_3'].value_counts()\n",
    "count_4 = df['words_4'].value_counts()\n",
    "count_5 = df['words_5'].value_counts()\n",
    "count_6 = df['words_6'].value_counts()\n",
    "count_7 = df['words_7'].value_counts()\n",
    "count_8 = df['words_8'].value_counts()\n",
    "\n",
    "words_all = pd.Series()\n",
    "words_all = pd.concat([words_0,words_all],axis = 0)\n",
    "words_all = pd.concat([words_1,words_all],axis = 0)\n",
    "words_all = pd.concat([words_2,words_all],axis = 0)\n",
    "words_all = pd.concat([words_3,words_all],axis = 0)\n",
    "words_all = pd.concat([words_4,words_all],axis = 0)\n",
    "words_all = pd.concat([words_5,words_all],axis = 0)\n",
    "words_all = pd.concat([words_6,words_all],axis = 0)\n",
    "words_all = pd.concat([words_7,words_all],axis = 0)\n",
    "words_all = pd.concat([words_8,words_all],axis = 0)\n",
    "words_all = set(words_all)\n",
    "\n",
    "df_count = pd.DataFrame(columns = ['count_0','count_1','count_2','count_3','count_4','count_5','count_6','count_7', 'count_8'], index = words_all)\n",
    "\n",
    "df_count['count_0'] = count_0\n",
    "df_count['count_1'] = count_1\n",
    "df_count['count_2'] = count_2\n",
    "df_count['count_3'] = count_3\n",
    "df_count['count_4'] = count_4\n",
    "df_count['count_5'] = count_5\n",
    "df_count['count_6'] = count_6\n",
    "df_count['count_7'] = count_7\n",
    "df_count['count_8'] = count_8\n",
    "\n",
    "df_count = df_count.sort_values(by=[\"count_0\"],ascending = False)\n",
    "\n",
    "df_count = df_count.sort_values(by=[\"count_0\"],ascending = False)\n",
    "kredit = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_1\"],ascending = False)\n",
    "ipoteka = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_2\"],ascending = False)\n",
    "restruct = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_3\"],ascending = False)\n",
    "vklad = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_4\"],ascending = False)\n",
    "bisnez = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_5\"],ascending = False)\n",
    "obslu = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_6\"],ascending = False)\n",
    "karta = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_7\"],ascending = False)\n",
    "perevod = df_count[0:100].index\n",
    "df_count = df_count.sort_values(by=[\"count_8\"],ascending = False)\n",
    "invest = df_count[0:100].index\n",
    "\n",
    "kredit = set(kredit)\n",
    "ipoteka = set(ipoteka)\n",
    "restruct = set(restruct)\n",
    "vklad = set(vklad)\n",
    "bisnez = set(bisnez)\n",
    "obslu = set(obslu)\n",
    "karta = set(karta)\n",
    "perevod = set(perevod)\n",
    "invest = set(invest)\n",
    "main_words = set()\n",
    "\n",
    "main_words = main_words.union(kredit,ipoteka,restruct,vklad,bisnez,obslu,karta,perevod,invest);\n",
    "same_words = kredit.intersection(kredit,ipoteka,restruct,vklad,bisnez,obslu,karta,perevod,invest)\n",
    "main_words = main_words.difference(same_words)\n",
    "main_words = pd.Series(list(main_words))\n",
    "final_words = pd.DataFrame(columns = ['words'])\n",
    "final_words['words'] = main_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Добавление новых признаков, обучение модели и предсказание результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train\n",
    "test = test\n",
    "words = np.array(final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.apply(lambda x: x['title'] + ' ' + x['text'], axis=1)\n",
    "test['text'] = test.apply(lambda x: x['title'] + ' ' + x['text'], axis=1)\n",
    "\n",
    "for i in words:\n",
    "    df[i[0]] = df['text'].apply(lambda x: int(i[0] in x))\n",
    "for i in words:\n",
    "    test[i[0]] = test['text'].apply(lambda x: int(i[0] in x))\n",
    "    \n",
    "df = df.drop('title', 1)\n",
    "df = df.drop('text', 1)\n",
    "df = df.drop('Unnamed: 0', 1)\n",
    "ids = test['Unnamed: 0']\n",
    "test = test.drop('title', 1)\n",
    "test = test.drop('text', 1)\n",
    "test = test.drop('Unnamed: 0', 1)\n",
    "\n",
    "X_train = df.drop('type', axis=1)\n",
    "y_train = df['type']\n",
    "\n",
    "logistic = LogisticRegression(C=0.2)\n",
    "logistic.fit(X_train, y_train)\n",
    "answers = logistic.predict(test)\n",
    "\n",
    "types = ['Кредит', 'Ипотека', 'Реструктуризация','Вклад','Бизнес услуги','Обслуживание физ. и юр. лиц','Дебетовая карта','Денежные переводы','Инвестиционные продукты']\n",
    "answers = list(map(lambda x: types[x], answers))\n",
    "\n",
    "sub = pd.DataFrame({'index': range(0, len(answers)), 'type': answers}) \n",
    "sub.to_csv('classif.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
